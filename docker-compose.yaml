services:
  zoo1: #tên service. Đây là zookeeper giúp quản lý kafka
    image: confluentinc/cp-zookeeper:7.3.2 #image với tag 7.3.2
    hostname: zoo1 #tên nội bộ của container
    container_name: zoo1 #tên bên ngoài của container
    ports:
      - "2181:2181" #mapping port bên ngoài là 2181 với port nội bộ là 2181
    environment: #các biến mỗi trường cần để cấu hình image cp-zookeeper
      ZOOKEEPER_CLIENT_PORT: 2181 #cổng client dùng để kết nối đến zookeeper
      ZOOKEEPER_SERVER_ID: 1 #mỗi zookeeper server cần 1 id => đặt là 1
      ZOOKEEPER_SERVERS: zoo1:2888:3888 #danh sách các server trong zookeeper cluster: port giao tiếp giữa các zookeepr: port bầu chọn leader
    networks:
      - broker-kafka #gắn container vào network (các container cùng network có thể giao tiếp nội bộ mà không cần mở port ra ngoài)

  kafka1: #tên service
    image: confluentinc/cp-kafka:7.3.2 #image kafka
    hostname: kafka1 #tên nội bộ của container
    container_name: kafka1 #tên bên ngoài của container
    ports:
      - "9092:9092" #mở 2 cổng cho kafka
      - "29092:29092"
    environment:
      #giúp thông báo đến listeners cách thức kết nối kafka
      #Internal: cách kết nối đến container này nếu cùng network
      #External: cách kết nối đến container này nếu nằm cùng network
      #Docker: dành cho ứng dụng chạy trong docker desktop
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      #phương thức bảo mật của từng cách kết nối
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      #các kafka broker sẽ khai báo với nhau qua internal
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      #kết nối zookeeper thông qua zoo1:2181 trong network
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      #id của kafka broker
      KAFKA_BROKER_ID: 1
      #cấu hình mức độ log của kafka
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      #bật bảo mật nhưng không khóa
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      #số parition mặc định
      KAFKA_NUM_PARTITIONS: 4
    #cần khởi động sau zoo1
    depends_on:
      - zoo1
    #network của container
    networks:
      - broker-kafka

  kafka2: #kafka giúp nhận dữ liệu từ bên ngoài vào
    image: confluentinc/cp-kafka:7.3.2 #image
    hostname: kafka2 #tên nội bộ
    container_name: kafka2 #tên bên ngoài
    ports:
      - "9093:9093" #nối với 2 port
      - "29093:29093"
    environment:
      #cách thức kết nối đến container này
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:19093,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093,DOCKER://host.docker.internal:29093
      #phương thức bảo mật
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      #kết nối giữa các broker thông qua internal
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      #nối với zookeeper zoo1
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      #id của broker này
      KAFKA_BROKER_ID: 2
      #set loại log trả về
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      #đặt bảo mật
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      KAFKA_NUM_PARTITIONS: 4
    #cần zoo1 khởi tọa trước
    depends_on:
      - zoo1
    networks:
      - broker-kafka

  
  kafka3:
    #Khởi tạo tương tự thêm 1 broker nữa ID là 3
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka3
    container_name: kafka3
    ports:
      - "9094:9094"
      - "29094:29094"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka3:19094,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9094,DOCKER://host.docker.internal:29094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      KAFKA_BROKER_ID: 3
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      KAFKA_NUM_PARTITIONS: 4
    depends_on:
      - zoo1
    networks:
      - broker-kafka

  kafdrop: #là một container giúp phục vụ web UI cho Kafka giúp trực quan rõ hon
     image: obsidiandynamics/kafdrop:3.27.0 #image
     container_name: kafdrop #tên container bên ngoài
     hostname: kafdrop #tên nội bộ container
     networks:
       - broker-kafka #chung network với 3 kafka và 1 zookeeper
     depends_on:
       - zoo1 #phụ thuộc vào zookeeper
     ports:
       - 19000:9000 #ánh xạ tới cổng 190000 bên ngoài => localhost:19000 giúp mở kafka drop UI
     environment: #kết nối ctowis 3 kafka
       KAFKA_BROKERCONNECT: kafka1:29092,kafka2:29093,kafka3:29094

  spark-master:
    build:
      context: .
      dockerfile: spark.Dockerfile
    container_name: spark-master
    user: root 
    ports:
      - "9090:8080" # Spark Master Web UI
      - "7077:7077" # Spark Master port
    volumes:
      - ./consumer:/app/consumer
      - ./requirements.txt:/app/requirements.txt
    environment:
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - PYTHONPATH=/app
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    networks:
      - broker-kafka
  spark-worker-1:
    build:
      context: .
      dockerfile: spark.Dockerfile
    container_name: spark-worker-1
    hostname: spark-worker-1
    user: root
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_WEBUI_PORT=8081
      - PYTHONPATH=/app
    volumes:
      - ./consumer:/app/consumer
      - ./requirements.txt:/app/requirements.txt
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    networks:
      - broker-kafka

  spark-worker-2:
    build:
      context: .
      dockerfile: spark.Dockerfile
    container_name: spark-worker-2
    hostname: spark-worker-2
    user: root
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_WEBUI_PORT=8082 
      - PYTHONPATH=/app
    volumes:
      - ./consumer:/app/consumer
      - ./requirements.txt:/app/requirements.txt
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    networks:
      - broker-kafka
  spark-submit-streaming:
    build:
      context: .
      dockerfile: spark.Dockerfile # Dùng chung image đã build
    container_name: spark-submit-streaming
    user: root
    hostname: spark-submit-streaming
    volumes:
      # Mount cả thư mục consumer
      - ./consumer:/app/consumer
      # Dòng mount jar (nếu cần)
      - ./packages/postgresql-42.5.4.jar:/opt/spark/jars/postgresql-4.5.4.jar
    environment:
      INFLUXDB_BUCKET: ${INFLUXDB_BUCKET}
      INFLUXDB_MEASUREMENT: ${INFLUXDB_MEASUREMENT}
      INFLUX_ORG: ${INFLUXDB_ORG}
      INFLUX_TOKEN: ${INFLUXDB_TOKEN}
      PYTHONPATH: /app
    
    # === SỬA LỖI Ở ĐÂY ===
    # Toàn bộ lệnh command phải nằm trên MỘT DÒNG
    command: sh -c "/opt/spark/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 --master spark://spark-master:7077 --py-files /app/consumer/InfluxDBWriter.py /app/consumer/consumer.py"
    # === KẾT THÚC SỬA LỖI ===

    depends_on:
      - spark-master
      - kafka1
      - kafka2
      - kafka3
      - influxdb
    networks:
      - broker-kafka


  influxdb:
    image: influxdb:2.7
    container_name: influxdb
    hostname: influxdb
    restart: always
    ports:
      - "8086:8086"
    volumes:
      - .\influxdb:/var/lib/influxdb2
    environment:
      INFLUXDB_USER: ${INFLUXDB_DB_USERNAME}
      INFLUXDB_ADMIN_USER_PASSWORD: ${INFLUXDB_DB_ADMIN_PASSWORD}
      INFLUXDB_USER_PASSWORD: ${INFLUXDB_DB_PASSWORD}
      INFLUXDB_DB: ${INFLUXDB}
      INFLUXDB_ORG: ${INFLUXDB_ORG}
      INFLUXDB_BUCKET: ${INFLUXDB_BUCKET}
      INFLUXDB_MEASUREMENT: ${INFLUXDB_MEASUREMENT}
      INFLUXDB_HTTP_AUTH_ENABLED: "true"
      INFLUXDB_ADMIN_USER_TOKEN: ${INFLUXDB_TOKEN}
      INFLUXDB_TOKEN: ${INFLUXDB_TOKEN}
    networks:
      - broker-kafka
    
networks:
  broker-kafka:
    driver: bridge